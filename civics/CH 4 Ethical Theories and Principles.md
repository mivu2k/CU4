
- **Moral Developments**
	Moral development refers to the process by which individuals and societies refine their understanding of ethical principles and apply them in decision-making. It help in guiding the individuals and society to address ethical issues in a rapidly evolving digital world.
	For example:
	1. Companies widely collected and sold user data without transparency, often violating privacy expectations.
	   **_Moral development:_** Over time, public regulations have shaped a stronger commitment to data privacy.
	2. Early AI models were trained on biased data without much awareness of the ethical implications, leading to biased outcomes in hiring, lending, and policing.
	  **_Moral development:_**  As awareness grew, fair algorithms replaced biased algorithms.

- **Deontology**
	An ethical theory based on rules and duties. It argues that certain actions are inherently right or wrong, regardless of their consequences. It is an ethical framework that focuses on **duty, rules,** and **obligations** rather than **consequences.**
	For example:
	1. A programmer refuses to copy proprietary code from a competitor, even if it would accelerate development.
	   **_Deontological Principle:_** Respect for intellectual property laws and ethical obligations.
	2. A developer informs management about a critical bug in a software release, even if delaying the launch affects profits.
	   **_Deontological Principle:_** Duty to uphold integrity and honesty.

- **Utilitarianism**
	Utilitarianism is an ethical theory that focuses on maximizing overall happiness and minimizing harm. It evaluates actions based on their consequences rather than fixed moral rules.  
	For example:
	1. A security researcher hacks into a system to expose vulnerabilities, preventing future cyberattacks that could harm millions.
	   **_Utilitarianism Principle:_** Short-term disruption is justified for long-term security.
	2. A developer development team fixes critical bugs affecting thousands of users first, even though smaller issues impact some users.
	   **_Utilitarianism Principle:_** Prioritizing actions that benefit the greatest number of people.

- **Virtue Theory**
	Virtue theory, or virtue ethics, focuses on the character and moral integrity of individuals rather than strict rules (deontology) or consequences (utilitarianism). It emphasizes traits like honesty, courage, and compassion.
	For example:
	1. A developer openly admits to a mistake in the code rather than covering it up, ensuring transparency and trust within the team.
	   **_Virtue:_** Honesty & Integrity
	2. An AI engineer ensures that machine learning models do not have racial or gender biases, even if it requires extra effort and resources.	
	   **_Virtue:_** Fairness & Justice

- **Rights Theory**
	It is an ethical framework that emphasizes the protection of individual rights and freedoms. It argues that every person has inherent rights, such as privacy, freedom of speech, and ownership, which must be respected in all ethical decision-making.
	For example:
	1. A social media platform allows users to express their opinions freely while balancing moderation policies to prevent harm.
	   **_Right protected:_** Right to free speech
	2. A software company ensures that open-source licenses are respected and does not use copyrighted code without permission.
	   **_Right protected:_** Right to intellectual property

- **Casuist Theory**
	It is an ethical approach that focuses on **case-based reasoning** rather than applying universal moral principles. Instead of following ethical rules (deontology) or maximizing benefits (utilitarianism), casuistry evaluates ethical dilemmas by comparing them to past cases with similar circumstances.
	For example:
	1. A security researcher finds a critical vulnerability in a major software system. They examine past ethical hacking cases (e.g., Google Project Zero’s responsible disclosure practices) to decide whether to inform the company privately or disclose it publicly.
	   **_Casuist Approach:_** Looking at similar security disclosures to make an ethical choice.
	2. A company wants to use AI for job screening but worries about bias. They analyze cases where companies faced legal action due to biased AI hiring decisions and adjust their model accordingly.
	   **_Casuist Approach:_** Using past legal and ethical cases to refine AI ethics.

- **Moral Absolutism**
	Moral absolutism is the ethical belief that certain actions are always right or wrong, regardless of context, consequences, or personal beliefs. It holds that there are universal moral truths that apply in all situations, regardless of context or consequences.
	For example:
	1. A cybersecurity expert refuses to hack into a competitor’s system, even if doing so would expose unethical practices or security flaws.
	   **_Absolute principle:_** Hacking is unethical, regardless of the reason.
	2. A software company refuses to sell user data to advertisers, even if doing so would generate significant revenue and improve services.
	   **_Right protected:_** Violating user privacy is absolutely wrong.

- **Moral Rationalism**
	It is the ethical theory that moral truths are discovered through reason and logic rather than emotions, cultural norms, or religious beliefs. It suggests that ethical decisions should be based on rational principles.
	For example:
	1. A company designing an AI system ensures it makes fair decisions using logical, unbiased algorithms, rather than relying on human intuition or societal biases.
	   **_Rationalist principle:_** Ethical AI should be designed using reason and fairness, not emotions or profit motives.
	2. A developer logically assesses whether including dark patterns (misleading UI tricks) in an app is ethical, concluding that deception harms users and is therefore wrong.
	   **_Right protected:_** Ethical software design should be based on rational principles of honesty and transparency.

- **Moral Pluralism**
	It is the ethical theory that multiple ethical principles may be valid and relevant in any situation and may sometimes conflict. The ethical reasoning must balance them rather than adhering strictly to one approach / principle.
	For example:
	1. An AI hiring system must be accurate (utilitarian), fair (deontological), and transparent (virtue ethics). A pluralist approach considers all these ethical values rather than prioritizing just one.
	   **_Pluralist approach:_** Ethical AI design requires balancing fairness, accuracy, and transparency.
	2. In an unavoidable accident, should an autonomous vehicle prioritize minimizing overall harm (utilitarianism), following traffic laws (deontology), or protecting its passengers (virtue ethics)?
	   **_Pluralist approach:_** AI decision-making to weigh multiple ethical perspectives.

- **Ethical Egoism**
	It is the ethical theory that individuals should act in their own self-interest. According to this view, an action is morally right if it benefits the individual, even if it does not prioritize the well-being of others.
	For example:
	1. A tech company collects and sells user data to advertisers for profit, despite privacy concerns.
	   **_Egoist Justification:_** Company’s financial growth is the priority, even if users feel exploited.
	2. A developer finds a security flaw in their company’s software but does not report it to avoid extra work or negative attention.
	   **_Egoist Justification::_** Avoiding blame or additional workload benefits the developer personally.

- **Feminist Consequentialism**
	It is an ethical framework that blends feminist ethics (which focuses on addressing gender inequalities and promoting social justice) with consequentialism (which evaluates actions based on their outcomes)
	For example:
	1. A company designing facial recognition software ensures that it works equally well for all genders and skin tones, preventing discrimination against women and minorities.
	   **_Feminist Justification:_** The best outcome is one that reduces bias and promotes fairness.
	2. A  hiring AI is programmed to avoid gender bias by removing names from resumes, ensuring equal opportunities for women in tech.
	   **_Feminist Justification:_** A more diverse workforce leads to better societal and company-wide benefits.

- **Moral Autonomy**
	It is the ability of individuals / system to make ethical decisions independently, based on rational judgment rather than external pressure. It emphasizes self-governance, critical thinking, and ethical responsibility in decision-making.
	For example:
	1. A programmer discovers that their company's algorithm unfairly discriminates against certain users. Despite pressure from leadership, they choose to report it, following their own moral reasoning.
	   **_Moral Autonomy:_** Developer acts based on personal judgment rather than corporate influence.
	2. Engineers refuse to work on autonomous weapons, believing that machines should not have the power to take human lives, even if the project is legal and profitable.
	   **_Moral Autonomy:_** Ethical engineers make independent moral choices about what projects to support without the external influence.